{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e199a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Shape of X_train: (3840, 4)\n",
      "Shape of X_test: (961, 4)\n",
      "Shape of y_train: (3840,)\n",
      "Shape of y_test: (961,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"NY-House-Dataset.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found.\")\n",
    "\n",
    "# Haversine formula to calculate distance between two points given their coordinates\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  \n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c \n",
    "    return distance\n",
    "\n",
    "iconic_landmark_coords = (40.7580, -73.9855)  # Times Square coordinates\n",
    "\n",
    "df['DISTANCE_TO_ICONIC_LANDMARK'] = df.apply(lambda row: haversine(row['LATITUDE'], row['LONGITUDE'], iconic_landmark_coords[0], iconic_landmark_coords[1]), axis=1)\n",
    "\n",
    "X = df[['BEDS', 'BATH', 'PROPERTYSQFT', 'DISTANCE_TO_ICONIC_LANDMARK']]\n",
    "y = df['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2ace9",
   "metadata": {},
   "source": [
    "### Initial Feature Selection Explanation\n",
    "\n",
    "**Features for X:**\n",
    "1. **Number of Bedrooms (`BEDS`):** The number of bedrooms in a house is often a significant factor in determining its price. Larger houses with more bedrooms tend to have higher prices.\n",
    "2. **Number of Bathrooms (`BATH`):** Similar to the number of bedrooms, the number of bathrooms is another essential feature influencing house prices. Houses with more bathrooms are typically more desirable and command higher prices.\n",
    "3. **Property Square Footage (`PROPERTYSQFT`):** The size of the property, measured in square footage, is a critical determinant of its value. Larger properties generally have higher prices compared to smaller ones.\n",
    "4. **Distance to Iconic Landmark (`DISTANCE_TO_ICONIC_LANDMARK`):** This newly engineered feature represents the distance of each house from an iconic landmark, such as Times Square. The proximity to famous landmarks or attractions can influence property prices, as houses located closer to popular destinations may command higher prices due to increased demand.\n",
    "\n",
    "**Target Feature y:**\n",
    "- **House Price (`PRICE`):** The target feature is the price of the house. It is a continuous variable representing the monetary value of the property. The goal of our analysis is to predict house prices based on the selected features.\n",
    "\n",
    "**Explanation:**\n",
    "- The selected features for X were chosen based on their known impact on house prices and their availability in the dataset. Features such as number of bedrooms, number of bathrooms, and property square footage are commonly used indicators of a house's value and are widely recognized by real estate professionals.\n",
    "- Latitude and longitude coordinates were included to capture the spatial aspect of property location, allowing us to account for differences in neighborhood desirability and amenities.\n",
    "- The engineered feature, distance to the iconic landmark, provides additional context by considering the proximity of each house to a prominent landmark. This feature aims to capture the influence of location relative to famous attractions on property prices.\n",
    "- By including these features in the predictive model, we aim to create a comprehensive understanding of the factors driving house prices in New York City and develop a robust model for predicting property values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462307d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Metrics (Train Set Only):\n",
      "Training RMSE: 47384.187923103505\n",
      "Training MAE: 1810.7429687500003\n",
      "Training R^2 Score: 0.9999981635070819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree_reg.predict(X_train)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Decision Tree Model Metrics (Train Set Only):\")\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Training MAE:\", train_mae)\n",
    "print(\"Training R^2 Score:\", train_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38c7fd",
   "metadata": {},
   "source": [
    "The decision tree model exhibits excellent performance on the training set, as evidenced by the following metrics:\n",
    "\n",
    "1. **Training RMSE:** The root mean squared error (RMSE) measures the average deviation of predicted values from actual values. A low RMSE indicates that the model's predictions are close to the actual values. In this case, the training RMSE of approximately 47384.19 suggests that the model's predictions have relatively small errors on average.\n",
    "\n",
    "2. **Training MAE:** The mean absolute error (MAE) represents the average absolute difference between predicted and actual values. Similar to RMSE, a lower MAE indicates better model performance. The training MAE of approximately 1810.74 indicates that, on average, the model's predictions are off by around 1810.74.\n",
    "\n",
    "3. **Training R^2 Score:** The coefficient of determination (R-squared) measures the proportion of the variance in the target variable that is predictable from the independent variables. A value close to 1 indicates that the model explains a large portion of the variance in the target variable. The training R^2 score of approximately 0.999998 suggests that the decision tree model fits the training data extremely well, capturing almost all of the variance in the house prices.\n",
    "\n",
    "Overall, the decision tree model demonstrates outstanding performance on the training set, achieving nearly perfect accuracy in predicting house prices. However, it's important to note that evaluating the model solely on the training set may not provide a complete picture of its generalization ability. Further evaluation on an independent test set is necessary to assess the model's performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9ffe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
